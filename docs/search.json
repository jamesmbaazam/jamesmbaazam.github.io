[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation\n\n\n\n\n\n\nforecasting\n\n\nEpiNow2\n\n\nBayesian Analysis\n\n\nReproduction numbers\n\n\nR\n\n\nStan\n\n\n\n\n\n\n\n\n\nNov 8, 2025\n\n\nJames Mba Azam\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n\nThis is a personal academic/professional website built with Quarto. The site showcases research, publications, open-source projects, teaching materials, and blog posts related to infectious disease modeling and epidemiological analytics.\nThe site is published at https://jamesmbaazam.github.io using GitHub Pages.\n\n\n\n\nQuarto: Static site generator for the website\nR: Primary programming language for blog posts and computational content\nrenv: R package dependency management\nGitHub Actions: CI/CD pipeline for automated publishing\n\n\n\n\n\n_quarto.yml: Main Quarto configuration file\nindex.qmd: Homepage\nblog.qmd: Blog listing page\nblog/: Individual blog posts (each in its own subdirectory with index.qmd)\n\nblog/epinow2-eval-guide/: Guide on evaluating EpiNow2 model runs\nblog/julia-sugar-vs-r/: Comparison of Julia and R syntax\n\nresearch_projects.qmd: Research and publications page\nopensource_projects.qmd: Open-source projects page\nteaching.qmd: Teaching materials page\nimages/: Static images for the site\nstyles.css: Custom CSS styles\n_extensions/: Quarto extensions (e.g., auto-dark mode)\ndocs/: Output directory for rendered site (published to GitHub Pages)\nrenv/: R package environment (managed by renv)\nrenv.lock: Locked R package dependencies\n\n\n\n\n\n\nquarto preview\n\n\n\nquarto render\n\n\n\nquarto render index.qmd\nquarto render blog/epinow2-eval-guide/index.qmd\n\n\n\nInitialize or restore R environment:\n# In R console\nrenv::restore()\nInstall new R packages:\n# In R console\ninstall.packages(\"package_name\")\nrenv::snapshot()  # Update renv.lock after installing\n\n\n\n\nBlog posts are written in Quarto markdown (.qmd) files located in subdirectories under blog/. Each post typically includes:\n\nYAML frontmatter with metadata (title, author, date, categories, ORCID)\nR code chunks (often with caching enabled via freeze: true for computationally intensive content)\nCategories include: forecasting, EpiNow2, Bayesian Analysis, Reproduction numbers, R, Stan, Julia\n\nBlog posts often use R packages like: - EpiNow2 (epidemiological nowcasting/forecasting) - data.table, dplyr (data manipulation) - ggplot2 (visualization) - bayesplot, posterior (Bayesian analysis) - scoringutils (forecast evaluation)\n\n\n\nThe site is automatically built and published to GitHub Pages on every push to main branch via .github/workflows/quarto-publish.yml. The workflow:\n\nSets up Quarto (pre-release version)\nSets up R\nRestores R environment using renv\nInstalls system dependency (GLPK for igraph package)\nRenders and publishes to gh-pages branch\n\n\n\n\n\nOutput directory: docs/ (configured in _quarto.yml)\nR version: 4.5.1 (as specified in renv.lock)\nTheme: cosmo (light), darkly (dark mode)\nAuto-dark filter: Automatically switches between light/dark themes\nSite navigation: Top navbar with Home, Research, Open-source Projects, Teaching, Blog\nSocial links: Twitter, GitHub, LinkedIn, Google Scholar, Email\n\n\n\n\n\nThe site uses renv for R package management. Always run renv::restore() when setting up a new environment.\nBlog posts with computationally intensive code use freeze: true to cache results and avoid re-execution on every render.\nThe GitHub Actions workflow requires GLPK to be installed for the igraph R package dependency.\nThe output directory is docs/ (not the default _site/), which is configured for GitHub Pages publishing."
  },
  {
    "objectID": "CLAUDE.html#project-overview",
    "href": "CLAUDE.html#project-overview",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This is a personal academic/professional website built with Quarto. The site showcases research, publications, open-source projects, teaching materials, and blog posts related to infectious disease modeling and epidemiological analytics.\nThe site is published at https://jamesmbaazam.github.io using GitHub Pages."
  },
  {
    "objectID": "CLAUDE.html#tech-stack",
    "href": "CLAUDE.html#tech-stack",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Quarto: Static site generator for the website\nR: Primary programming language for blog posts and computational content\nrenv: R package dependency management\nGitHub Actions: CI/CD pipeline for automated publishing"
  },
  {
    "objectID": "CLAUDE.html#repository-structure",
    "href": "CLAUDE.html#repository-structure",
    "title": "CLAUDE.md",
    "section": "",
    "text": "_quarto.yml: Main Quarto configuration file\nindex.qmd: Homepage\nblog.qmd: Blog listing page\nblog/: Individual blog posts (each in its own subdirectory with index.qmd)\n\nblog/epinow2-eval-guide/: Guide on evaluating EpiNow2 model runs\nblog/julia-sugar-vs-r/: Comparison of Julia and R syntax\n\nresearch_projects.qmd: Research and publications page\nopensource_projects.qmd: Open-source projects page\nteaching.qmd: Teaching materials page\nimages/: Static images for the site\nstyles.css: Custom CSS styles\n_extensions/: Quarto extensions (e.g., auto-dark mode)\ndocs/: Output directory for rendered site (published to GitHub Pages)\nrenv/: R package environment (managed by renv)\nrenv.lock: Locked R package dependencies"
  },
  {
    "objectID": "CLAUDE.html#development-commands",
    "href": "CLAUDE.html#development-commands",
    "title": "CLAUDE.md",
    "section": "",
    "text": "quarto preview\n\n\n\nquarto render\n\n\n\nquarto render index.qmd\nquarto render blog/epinow2-eval-guide/index.qmd\n\n\n\nInitialize or restore R environment:\n# In R console\nrenv::restore()\nInstall new R packages:\n# In R console\ninstall.packages(\"package_name\")\nrenv::snapshot()  # Update renv.lock after installing"
  },
  {
    "objectID": "CLAUDE.html#blog-post-structure",
    "href": "CLAUDE.html#blog-post-structure",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Blog posts are written in Quarto markdown (.qmd) files located in subdirectories under blog/. Each post typically includes:\n\nYAML frontmatter with metadata (title, author, date, categories, ORCID)\nR code chunks (often with caching enabled via freeze: true for computationally intensive content)\nCategories include: forecasting, EpiNow2, Bayesian Analysis, Reproduction numbers, R, Stan, Julia\n\nBlog posts often use R packages like: - EpiNow2 (epidemiological nowcasting/forecasting) - data.table, dplyr (data manipulation) - ggplot2 (visualization) - bayesplot, posterior (Bayesian analysis) - scoringutils (forecast evaluation)"
  },
  {
    "objectID": "CLAUDE.html#publishing-workflow",
    "href": "CLAUDE.html#publishing-workflow",
    "title": "CLAUDE.md",
    "section": "",
    "text": "The site is automatically built and published to GitHub Pages on every push to main branch via .github/workflows/quarto-publish.yml. The workflow:\n\nSets up Quarto (pre-release version)\nSets up R\nRestores R environment using renv\nInstalls system dependency (GLPK for igraph package)\nRenders and publishes to gh-pages branch"
  },
  {
    "objectID": "CLAUDE.html#key-configuration-details",
    "href": "CLAUDE.html#key-configuration-details",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Output directory: docs/ (configured in _quarto.yml)\nR version: 4.5.1 (as specified in renv.lock)\nTheme: cosmo (light), darkly (dark mode)\nAuto-dark filter: Automatically switches between light/dark themes\nSite navigation: Top navbar with Home, Research, Open-source Projects, Teaching, Blog\nSocial links: Twitter, GitHub, LinkedIn, Google Scholar, Email"
  },
  {
    "objectID": "CLAUDE.html#important-notes",
    "href": "CLAUDE.html#important-notes",
    "title": "CLAUDE.md",
    "section": "",
    "text": "The site uses renv for R package management. Always run renv::restore() when setting up a new environment.\nBlog posts with computationally intensive code use freeze: true to cache results and avoid re-execution on every render.\nThe GitHub Actions workflow requires GLPK to be installed for the igraph R package dependency.\nThe output directory is docs/ (not the default _site/), which is configured for GitHub Pages publishing."
  },
  {
    "objectID": "expertise.html",
    "href": "expertise.html",
    "title": "Expertise",
    "section": "",
    "text": "My current work centers on two key areas:\n\n\nI am analyzing the utility of wastewater surveillance for routine monitoring of multiple infectious diseases in South Africa. This work explores how environmental surveillance can complement traditional disease monitoring systems and provide early warning signals for public health action.\n\n\n\nI am developing mathematical and statistical models to map polio immunity and predict the risk of polio outbreaks across Africa. This is work in early stages."
  },
  {
    "objectID": "expertise.html#current-research-focus",
    "href": "expertise.html#current-research-focus",
    "title": "Expertise",
    "section": "",
    "text": "My current work centers on two key areas:\n\n\nI am analyzing the utility of wastewater surveillance for routine monitoring of multiple infectious diseases in South Africa. This work explores how environmental surveillance can complement traditional disease monitoring systems and provide early warning signals for public health action.\n\n\n\nI am developing mathematical and statistical models to map polio immunity and predict the risk of polio outbreaks across Africa. This is work in early stages."
  },
  {
    "objectID": "expertise.html#research-interests-methods",
    "href": "expertise.html#research-interests-methods",
    "title": "Expertise",
    "section": "Research Interests & Methods",
    "text": "Research Interests & Methods\nI hold a PhD specializing in outbreak response modeling and decision-making. My work focuses on developing methods and open-source tools to evaluate the impact of pharmaceutical and non-pharmaceutical interventions on the spread of vaccine-preventable diseases.\nKey areas of expertise:\n\nCompartmental modeling to quantify intervention impacts during epidemics\nReal-time forecasting and nowcasting of infections and \\(R_t\\) using Bayesian methods with tools like EpiNow2, epinowcast, and EpiEstim\nReproducible pipelines and open-source packages for outbreak analytics and model implementation\nBayesian data analysis for infectious disease problems\nSoftware development for epidemiological applications"
  },
  {
    "objectID": "expertise.html#other-ongoing-research-projects",
    "href": "expertise.html#other-ongoing-research-projects",
    "title": "Expertise",
    "section": "Other Ongoing Research Projects",
    "text": "Other Ongoing Research Projects\n\nEvaluating the tradeoffs of using temporally aggregated data for epidemiological forecasts: A case study of COVID-19 in South Africa\nCOVID-19 severity surveillance pipeline: Detecting changes in reported case fatality, case hospitalization, and hospital fatality rates\nTwo-strain variant emergence model: Studying the impact of the timing of variant emergence on control strategies"
  },
  {
    "objectID": "expertise.html#how-im-sharpening-my-skills",
    "href": "expertise.html#how-im-sharpening-my-skills",
    "title": "Expertise",
    "section": "How I‚Äôm Sharpening My Skills",
    "text": "How I‚Äôm Sharpening My Skills\nüñ•: Currently learning:\n\nProgramming in The Julia Porgramming Language\nForecasting principles and methods:\n\nBook: Forecasting: Principles and Practice (3rd ed)\nCourse: Nowcasting and forecasting infectious disease dynamics\n\nBayesian data analysis:\n\nBook: Statistical Rethinking\n\nOpen source software development:\n\nWorking in Public: The Making and Maintenance of Open Source Software\nPractical MLOps: Operationalizing Machine Learning Models\n\n\nüìñ: Casual reading:\n\nThe 5 Elements of Effective Thinking by Edward Burger and Michael Starbird\nThe Art of Explanation: How to Communicate with Clarity and Confidence by Ros Atkins"
  },
  {
    "objectID": "expertise.html#potential-collaborations",
    "href": "expertise.html#potential-collaborations",
    "title": "Expertise",
    "section": "Potential Collaborations",
    "text": "Potential Collaborations\nI am interested in collaborating on mathematical or statistical methods and models that advance outbreak analytics. We can also explore how to translate these innovations into practical software tools.\nPlease get in touch through any of my contacts below."
  },
  {
    "objectID": "expertise.html#contact-information",
    "href": "expertise.html#contact-information",
    "title": "Expertise",
    "section": "Contact Information",
    "text": "Contact Information\nFeel free to reach out through any of these channels:\n\nLinkedIn: James Azam, PhD\nTwitter: @james_azam\nGitHub: jamesmbaazam"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html",
    "href": "blog/epinow2-eval-guide/index.html",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "",
    "text": "library(EpiNow2)\nlibrary(posterior)\nlibrary(bayesplot)\nlibrary(data.table)\nlibrary(scoringutils)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#introduction",
    "href": "blog/epinow2-eval-guide/index.html#introduction",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Introduction",
    "text": "Introduction\nThis is a comprehensive guide on validating time-varying reproduction number (Rt) estimates from EpiNow2 model runs. EpiNow2 is a Bayesian framework for estimating Rt‚Äîa key epidemiological metric indicating disease transmission dynamics‚Äîand generating forecasts of case counts. Rigorous validation of these estimates is essential for reliable inference and evidence-based decision-making in infectious disease surveillance and outbreak response.\n\n\n\n\n\n\nWhat is the Reproduction Number (Rt)?\n\n\n\nThe time-varying reproduction number (Rt) represents the average number of secondary infections caused by an infected individual at time t. It‚Äôs a critical metric for understanding epidemic dynamics:\n\nRt &gt; 1: Epidemic is growing (each case generates more than one new case)\nRt = 1: Epidemic is stable (endemic equilibrium)\nRt &lt; 1: Epidemic is declining (heading toward extinction)\n\nUnlike the basic reproduction number (R0), which assumes a fully susceptible population, Rt accounts for changing conditions like interventions, behavior changes, and population immunity.\n\n\n\n\n\n\n\n\nEpiNow2 uses a Stan backend\n\n\n\n\n\n{EpiNow2} uses Stan in the backend for model specification, fitting, and inference.\nThis means that the model fit can be assessed using the same tools and techniques used for any Stan model. The EpiNow2 package provides a convenient interface to run the models, but the underlying model is a Stan model.\nThe returned fit object is either a &lt;stanfit&gt; or CmdStanModel object, depending on the backend ({rstan} or {cmdstanr}) used. For example, you can use the {bayesplot} and {posterior} packages to visualize and summarize the model diagnostics.\n\n\n\nValidating EpiNow2 Rt estimates requires a three-pillar approach: (1) MCMC diagnostics to ensure the Bayesian sampler has converged and is sampling efficiently from the posterior distribution, (2) convergence checks to verify reliable parameter estimates (via metrics like Rhat and effective sample size), and (3) forecast evaluation to assess predictive performance against observed data using proper scoring rules. This guide demonstrates each component using the Stan ecosystem‚Äôs diagnostic tools (bayesplot, posterior) and the scoringutils package for forecast scoring.\nWe‚Äôll demonstrate this workflow by running an example EpiNow2 model for Rt estimation, examining MCMC diagnostics and convergence metrics, and evaluating forecast performance using proper scoring rules."
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#running-an-example-model",
    "href": "blog/epinow2-eval-guide/index.html#running-an-example-model",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Running an example model",
    "text": "Running an example model\n\nInput preparation\nThis will involve: loading required packages, setting up the model parameters, and running the model.\n\n# Set number of cores for parallel processing.\noptions(mc.cores = min(4, parallel::detectCores() - 1))\n\n\n# Set example generation time, incubation period, and reporting delay. In practice, these should use estimates from the literature or be estimated from data.\ngeneration_time &lt;- Gamma(\n    shape = Normal(1.3, 0.3),\n    rate = Normal(0.37, 0.09),\n    max = 14\n)\n\nincubation_period &lt;- LogNormal(\n    meanlog = Normal(1.6, 0.06),\n    sdlog = Normal(0.4, 0.07),\n    max = 14\n)\nreporting_delay &lt;- LogNormal(mean = 2, sd = 1, max = 10)\n\n# Use example case data.\n\nreported_cases &lt;- example_confirmed[1:60]\n\n# Plot the data\ncases_plots &lt;- ggplot(reported_cases, aes(x = date, y = confirm)) +\n    geom_col() +\n    labs(title = \"Confirmed cases\", x = \"Date\", y = \"Cases\") +\n    theme_minimal()\n\ncases_plots\n\n\n\n\n\n\n\n\n\n\nFitting the model\nEstimate Rt and nowcast/forecast cases by date of infection.\n\nout &lt;- epinow(\n    data = reported_cases,\n    generation_time = gt_opts(generation_time),\n    rt = rt_opts(prior = LogNormal(mean = 2, sd = 0.1)),\n    delays = delay_opts(incubation_period + reporting_delay)\n)\n\nLogging threshold set at INFO for the name logger\nWriting EpiNow2 logs to the console and:\n'/var/folders/vr/dn4r1_zj417drd1zr9301trw0000gp/T//RtmpMm2rHx/regional-epinow/2020-04-21.log'.\nLogging threshold set at INFO for the name logger\nWriting EpiNow2.epinow logs to the console and:\n'/var/folders/vr/dn4r1_zj417drd1zr9301trw0000gp/T//RtmpMm2rHx/epinow/2020-04-21.log'.\n\n# Plot the model fit\nplot(out)"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#assessing-model-diagnostics",
    "href": "blog/epinow2-eval-guide/index.html#assessing-model-diagnostics",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Assessing model diagnostics",
    "text": "Assessing model diagnostics\nWe‚Äôll first extract the Stan fit object and compute diagnostics. The epinow() function returns a list of model outputs, including the Stan fit object. This is what we need to assess the model fit. Stan provides diagnostic metrics to assess the model fit, convergence, etc. which we‚Äôll use to assess the model fit. The Stan ecosystem has a rich set of tools for diagnosing model fit, including the bayesplot and posterior packages. These tools provide a way to visualize and summarize the model diagnostics. For an indepth look at MCMC diagnostics, for example, see the bayesplot R package vignette on visual MCMC diagnostics. You can also do posterior predictive checks using the bayesplot package.\nDiagnostics include:\n\nDivergent transitions. These should be minimized; ideally 0. Divergent transitions can be improved by tuning Stan controls like adapt_delta, max_treedepth, and stepsize in stan_opts(). If there are divergent transitions, increase adapt_delta (e.g., 0.95 or 0.99). See an in‚Äëdepth explanation at https://mc-stan.org/learn-stan/diagnostics-warnings.html.\nRhat. These should be close to 1 indicating good mixing. Rhat values should be less than 1.05 (See ?rstan::Rhat).\nTreedepth. This should be low; high values indicate potential issues with the model.\nESS values. These should be high; low values indicate insufficient sampling. In particular, both bulk‚ÄëESS and tail‚ÄëESS should be at least ~100 per chain to ensure reliable posterior quantile estimates (see ?rstan::ess_bulk).\n\n\nfit &lt;- out$estimates$fit\n\nnp &lt;- bayesplot::nuts_params(fit)\ndivergence_data &lt;- subset(np, Parameter == \"divergent__\")\ntreedepth_data &lt;- subset(np, Parameter == \"treedepth__\")\n\nposterior_summary &lt;- posterior::summarize_draws(\n    fit, c(posterior::default_convergence_measures(), \"ess_basic\")\n) |&gt; subset(variable != \"lp__\")\n\nfit_ess_basic &lt;- min(posterior_summary$ess_basic, na.rm = TRUE)\nfit_ess_bulk &lt;- min(posterior_summary$ess_bulk, na.rm = TRUE)\nfit_ess_tail &lt;- min(posterior_summary$ess_tail, na.rm = TRUE)\n\ndiagnostics &lt;- data.table(\n    \"samples\" = nrow(np) / length(unique(np$Parameter)),\n    \"max_rhat\" = round(max(posterior_summary$rhat, na.rm = TRUE), 3),\n    \"divergent_transitions\" = sum(divergence_data$Value),\n    \"per_divergent_transitions\" = mean(divergence_data$Value),\n    \"max_treedepth\" = max(treedepth_data$Value),\n    \"ess_basic\" = fit_ess_basic,\n    \"ess_bulk\" = fit_ess_bulk,\n    \"ess_tail\" = fit_ess_tail\n)\n\ndiagnostics[, no_at_max_treedepth :=\n                sum(treedepth_data$Value == max_treedepth)\n][, per_at_max_treedepth := no_at_max_treedepth / samples]\n\nknitr::kable(diagnostics)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsamples\nmax_rhat\ndivergent_transitions\nper_divergent_transitions\nmax_treedepth\ness_basic\ness_bulk\ness_tail\nno_at_max_treedepth\nper_at_max_treedepth\n\n\n\n\n2000\n1.01\n0\n0\n9\n1325.989\n1277.945\n1109.327\n837\n0.4185"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#evaluating-forecast-performance",
    "href": "blog/epinow2-eval-guide/index.html#evaluating-forecast-performance",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Evaluating forecast performance",
    "text": "Evaluating forecast performance\nForecast performance can be evaluated by comparing the forecast of reported cases with the observed cases using Proper Scoring Rules(Gneiting and Raftery 2007; Carvalho 2016) such as the Continuous Ranked Probability Score (CRPS) and Weighted Interval Score (WIS). These are available via the scoringutils::score() function.\nThe scoringutils::score() function requires a dataset that contains at least the following columns:\n\ndate: the date of the forecast\nprediction: forecast values\ntrue_value: the observed values\nquantile: If evaluating quantiles, the quantile of the forecasted values (e.g., median, lower and upper bounds), in ascending order.\n\nLet‚Äôs extract and prepare the forecasts and corresponding observed cases for the evaluation.\nEpiNow2‚Äôs epinow() function returns a list of model outputs in the raw and several summarised formats for various use cases. In particular, there are time series of ‚Äúinfections‚Äù, ‚Äúreported_cases‚Äù, ‚Äúgrowth_rate‚Äù, and ‚ÄúR‚Äù, all grouped into ‚Äúestimate‚Äù, ‚Äúestimate based on partial data‚Äù, and ‚Äúforecast‚Äù.\nHere, we‚Äôre interested in the ‚Äúforecast‚Äù type of the ‚Äúreported_cases‚Äù variable, including the median and quantiles (lower and upper bounds).\n\n# Extract the forecasts\nforecasts &lt;- out$estimates$summarised[variable == \"reported_cases\"][type == \"forecast\", ] %&gt;% \n    select(-c(mean, sd, variable, strat, type))\n\nLet‚Äôs also extract the corresponding subset of the observed data.\n\n# Extract observed cases for the same period\nobs_data &lt;- example_confirmed[date &gt;= min(forecasts$date) & date &lt;= max(forecasts$date)]\n\nNow, let‚Äôs combine the extracted forecasts with the observed data and clean up the quantiles into a format suitable for use with scoringutils. We will be cleaning them up because the forecasts data.table labels the quantiles as lower_20, upper_20, etc., where the number indicates the quantile level (e.g., 50% for the median), but that is not compatible with scoringutils.\n\n# Combine forecasts with observed cases\neval_dt &lt;- merge(forecasts, obs_data, by = \"date\")[, true_value := confirm][, confirm := NULL]\n\n# Melt the data to long format\ncols_to_melt &lt;- c(\"median\", grep(\"^(lower|upper)_\", names(eval_dt), value = TRUE))\neval_long &lt;- melt(\n    eval_dt,\n    id.vars = setdiff(names(eval_dt), cols_to_melt),\n    measure.vars = cols_to_melt,\n    variable.name = \"prediction\",\n    value.name = \"value\"\n)\n\n# Prepare the evaluation data\neval_long[, quantile := fifelse(\n  prediction == \"median\", 0.5,\n  fifelse(\n    grepl(\"^lower_\", prediction),\n    (1 - as.numeric(sub(\"lower_\", \"\", prediction)) / 100) / 2,\n    fifelse(\n      grepl(\"^upper_\", prediction),\n      (1 + as.numeric(sub(\"upper_\", \"\", prediction)) / 100) / 2,\n      NA_real_\n    )\n  )\n)][, prediction := value][, value := NULL]\n\nWarning in fifelse(grepl(\"^lower_\", prediction), (1 - as.numeric(sub(\"lower_\",\n: NAs introduced by coercion\n\n\nWarning in fifelse(grepl(\"^upper_\", prediction), (1 + as.numeric(sub(\"upper_\",\n: NAs introduced by coercion\n\n# Sort the data by quantile\nsetorder(eval_long, quantile) %&gt;% \n    head(10)\n\n          date true_value prediction quantile\n        &lt;Date&gt;      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n 1: 2020-04-22       2729    1526.00     0.05\n 2: 2020-04-23       3370    1623.90     0.05\n 3: 2020-04-24       2646    1911.95     0.05\n 4: 2020-04-25       3021    1599.00     0.05\n 5: 2020-04-26       2357    1701.95     0.05\n 6: 2020-04-27       2324    1507.00     0.05\n 7: 2020-04-28       1739    1237.85     0.05\n 8: 2020-04-22       2729    1895.00     0.25\n 9: 2020-04-23       3370    2056.75     0.25\n10: 2020-04-24       2646    2420.00     0.25\n\n\nNow we can use the scoringutils package to compute and summarise the scores. By default, a range of scores will be computed, including the interval_score, dispersion, underprediction, overprediction, coverage_deviation, bias, and ae_median.\n\n# Mainly uses the scoringutils package\nscored_scores &lt;- eval_long[, quantile_level := quantile][, quantile := NULL][, model := \"EpiNow2\"] |&gt; # align names to scoringutils preference\n    as_forecast_quantile(observed  = \"true_value\", predicted = \"prediction\") |&gt; \n    score() %&gt;%\n    summarise_scores()\n\nWarning: ! Computation for `interval_coverage_90` failed. Error: ! To compute the\n  interval coverage for an interval range of \"90%\", the 0.05 and 0.95 quantiles\n  are required.\n\nknitr::kable(scored_scores, digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\nwis\noverprediction\nunderprediction\ndispersion\nbias\ninterval_coverage_50\nae_median\n\n\n\n\nEpiNow2\n313.898\n33.963\n150.892\n129.043\n-0.143\n0.571\n444.286"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#interpretation-of-scores",
    "href": "blog/epinow2-eval-guide/index.html#interpretation-of-scores",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Interpretation of scores",
    "text": "Interpretation of scores\nThe table above provides a summary of the forecast performance across multiple metrics. However, interpreting these scores in isolation can be challenging, as they are not relative to other models. Proper scoring rules are most informative when comparing multiple models or against baseline forecasts.\nLet‚Äôs understand what each metric tells us:\n\ninterval_score: Overall forecast accuracy combining sharpness (narrow intervals) and calibration (actual coverage). Lower is better.\ndispersion: Measures the width of prediction intervals. Lower values indicate sharper (more confident) forecasts.\nunderprediction and overprediction: Penalties for forecasts that systematically miss below or above observations.\ncoverage_deviation: Difference between nominal and empirical coverage of prediction intervals. Values near zero indicate well-calibrated intervals.\nbias: Systematic tendency to over- or under-forecast. Values near zero are ideal.\nae_median: Absolute error of the median forecast. A simple point forecast accuracy metric.\n\nFor this example run, well-performing models should show low interval scores, minimal bias, and coverage deviation close to zero\n\n\n\n\n\n\nComparing against a baseline model\n\n\n\nA common practice is to have a baseline model (Stapper and Funk 2025), such as a naive model, and compare the scores of your model against it."
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#future-updates",
    "href": "blog/epinow2-eval-guide/index.html#future-updates",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Future updates",
    "text": "Future updates\nIn future updates, I will explore more advanced techniques for model diagnostics and evaluation, including posterior predictive checks, cross-validation, and more using packages like loo, shinystan, and bayesplot"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#resources",
    "href": "blog/epinow2-eval-guide/index.html#resources",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Resources",
    "text": "Resources\nFor more in-depth information on advanced model diagnostics and forecast evaluation techniques, I recommend the following resources:\n\nMCMC Diagnostics and Stan\n\nStan Diagnostics Guide: Official guide on diagnosing and resolving MCMC convergence issues, including detailed explanations of divergences, Rhat, and ESS.\nbayesplot Visual MCMC Diagnostics: Comprehensive tutorial on using trace plots, rank plots, and other visual diagnostics to assess MCMC performance.\nPosterior Predictive Checks: Guide to validating model fit by comparing simulated data from the posterior to observed data.\n\n\n\nForecast Evaluation\n\nUnderstanding, Evaluating, and Improving Forecasts of Infectious Disease Burden: Open course covering forecast methodology, proper scoring rules, and evaluation best practices specific to infectious disease applications.\nscoringutils R package: Documentation for computing and visualizing forecast scores (CRPS, WIS, interval score, etc.) with practical examples.\nscoringRules R package: Theoretical foundations and implementations of proper scoring rules for probabilistic forecasts.\n\n\n\nEpiNow2 Documentation\n\nEpiNow2 package website: Official documentation with function references, vignettes, and usage examples.\nEpiNow2 GitHub: Source code, issue tracker, and community discussions for troubleshooting and feature requests."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dr. James M. Azam",
    "section": "",
    "text": "Hi there, I am a Research Fellow at the London School of Hygiene and Tropical Medicine, based at the Centre for Mathematical Modelling of Infectious Diseases (CMMID), where I work with Dr.¬†Kathleen O‚ÄôReilly on:\n\nAnalyzing the utility of wastewater surveillance for routine monitoring of infectious diseases in South Africa\nDeveloping mathematical and statistical models to predict the risk of polio outbreaks in Africa\n\nPreviously, I was a Research Software Engineer with the Epiverse-TRACE Initiative, developing and maintaining R packages for reproducible analytics during epidemics.\nI am passionate about developing models, methods, and software that improve our understanding of disease transmission and enhance outbreak response.\n\n\n\n2022: PhD Applied Mathematics, Stellenbosch University, South Africa\n2018: MSc Mathematics, Stellenbosch University, South Africa\n2015: MSc Mathematical Sciences, African Institute for Mathematical Sciences (AIMS), Senegal\n2013: BSc Actuarial Science, Kwame Nkrumah University of Science and Technology, Ghana"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Dr. James M. Azam",
    "section": "",
    "text": "2022: PhD Applied Mathematics, Stellenbosch University, South Africa\n2018: MSc Mathematics, Stellenbosch University, South Africa\n2015: MSc Mathematical Sciences, African Institute for Mathematical Sciences (AIMS), Senegal\n2013: BSc Actuarial Science, Kwame Nkrumah University of Science and Technology, Ghana"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "I don‚Äôt currently teach as part of my duties but I can teach the following topics quite comfortably:\n\nR programming from the basics to advanced topics (R package development, object-oriented programming)\nGit/GitHub from the basics to intermediate/advanced (merging and rebasing, cherry-picking, etc)\nReproducible data analysis workflows\nVarious topics in mathematical/statistical/dynamical modelling of infectious diseases\nVarious topics in data analysis\nThesis and journal article writing techniques\n\nIn the past, I‚Äôve taught the following courses:\n\nA shortcourse on Introduction to R: Management, Exploration, and Communication of Data at the DSI-NRF Centre of Excellence in Epidemiological Modelling and Analysis (SACEMA) at Stellenbosch University in South Africa.\nI also have a YouTube channel with over 3000 subscribers with videos like this tutorial on Mendeley amassing over 35, 000 views.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "opensource_projects.html",
    "href": "opensource_projects.html",
    "title": "Open-source Projects",
    "section": "",
    "text": "The following are open-source projects that I lead or contribute to:\n\nepichains: a successor of bpmodels, which is an R package for analysing the distribution of the size and length of transmission chains.\nEpiNow2: An R package to estimate the time-varying reproduction number, growth rate, and doubling time using a range of open-source tools and best practices.\nepinowcast: An R package that provides flexible and efficient methods to gain situational awareness during outbreaks using currently available epidemiological observations and the reporting patterns of historical observations.\nEpiverse Initiative: An initiative that aims provide an integrated, generalisable, and scalable community-driven software ecosystem for outbreak analytics.\n\nFind my GitHub page here.\nI also,\n\nReview open source R code/packages for journals like the Journal of Open Source Software. Do reach out if you need my services.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "You can find my published work on my Google Scholar profile."
  },
  {
    "objectID": "publications.html#recent-work",
    "href": "publications.html#recent-work",
    "title": "Publications",
    "section": "Recent work",
    "text": "Recent work"
  },
  {
    "objectID": "publications.html#top-5-most-cited-publications",
    "href": "publications.html#top-5-most-cited-publications",
    "title": "Publications",
    "section": "Top 5 most cited publications",
    "text": "Top 5 most cited publications"
  },
  {
    "objectID": "software_teaching.html",
    "href": "software_teaching.html",
    "title": "Software & Teaching",
    "section": "",
    "text": "Below is a summary of my open source contributions. Find my GitHub page here.\nI also review open-source R code and packages for journals like the Journal of Open Source Software.\nDo reach out if you need my services."
  },
  {
    "objectID": "software_teaching.html#open-source-software",
    "href": "software_teaching.html#open-source-software",
    "title": "Software & Teaching",
    "section": "Open-Source Software",
    "text": "Open-Source Software\n\n\n  \n\n\nI lead and contribute to several open-source communities developing R packages for outbreak analytics. You can explore all my code on GitHub.\n\nEpiverse TRACE\nDuring my time as a Research Software Engineer with the Epiverse-TRACE Initiative, I:\n\nDeveloped epichains as a successor of bpmodels for analyzing the distribution of the size and length of transmission chains\nCo-maintained EpiNow2 for estimating the time-varying reproduction number, growth rate, and doubling time using Bayesian methods\n\n\n\nepiforecasts community\nI contribute to:\n\nEpiNow2: Estimates the time-varying reproduction number, growth rate, and doubling time using a range of open-source tools and Bayesian methods\nscoringutils: Tools for scoring and assessing predictions\n\n\n\nepinowcast community\nI contribute to:\n\nepinowcast: Provides flexible and efficient methods for gaining situational awareness during outbreaks using currently available epidemiological observations and the reporting patterns of historical observations\n\n\n\nThe Carpentries\nI briefly co-maintained the Carpentries course on Data Analysis and Visualization in R for Ecologists"
  },
  {
    "objectID": "software_teaching.html#teaching-outreach",
    "href": "software_teaching.html#teaching-outreach",
    "title": "Software & Teaching",
    "section": "Teaching & Outreach",
    "text": "Teaching & Outreach\n\nCurrent Teaching\nI am the lead facilitator for the Modelling for Pandemic Preparedness and Response (MPPR) modular shortcourse hosted by The German-West African Centre for Global Health and Pandemic Prevention (G-WAC) at the College of Health Sciences, Kwame Nkrumah University of Science and Technology (KNUST), Kumasi, Ghana.\nCourse Objectives/Learning Outcomes:\nAt the end of the course, participants are expected to:\n\nUnderstand the concepts of infectious disease transmission and control\nEnhance knowledge about data sources, data access, and data curation in (West) Africa\nDesign, implement and use context-specific mathematical models using the R programming language\nImprove knowledge of communication about modeling output\nBecome part of a network of disease modelers with an interest in West Africa\n\nWe have successfully delivered two iterations of this course in 2024 and 2025.\nI also maintain a YouTube channel with over 3,500 subscribers, featuring tutorials like this Mendeley tutorial with over 36,000 views.\n\n\nTeaching Competencies\n\nMathematical/statistical/dynamical modeling of infectious diseases\n\nIntroduction to Compartmental Models including methods for estimating the basic reproduction number. See example materials.\nModel fitting techniques. See example materials.\nBasics of branching process models for infectious disease modelling\nIntroduction to Bayesian Models for Infectious Disease Forecasting\nDeveloping generative Bayesian models for forecasting infectious diseases\nForecast evaluation using metrics such as Proper Scoring Rules\n\nReproducible data analysis workflows\n\nR programming from the basics to advanced topics (package development, object-oriented programming)\nResearch software/code development best practices\nGit/GitHub from the basics to intermediate/advanced (merging and rebasing, cherry-picking, etc.)\nR package development using software engineering industry standards\nPipeline orchestration with GNU make and the targets R package\nReproducible environments and research code portability (docker, renv, etc)\n\nEvidence synthesis\n\nSystematic/scoping review methods and free automation tools like Rayyan. See my YouTube tutorials\n\nThesis and journal article writing techniques\n\n\n\nPrevious Teaching Experience\n\nShort course on Introduction to R: Management, Exploration, and Communication of Data at the DSI-NRF Centre of Excellence in Epidemiological Modelling and Analysis (SACEMA) at Stellenbosch University, South Africa"
  },
  {
    "objectID": "research_projects.html",
    "href": "research_projects.html",
    "title": "Research",
    "section": "",
    "text": "I hold a PhD specialising in outbreak response modelling and decision-making. My work focuses on developing methods and open-source tools to evaluate the impact of pharmaceutical and non-pharmaceutical interventions on the spread of vaccine-preventable diseases.\nKey interests:\n\nCompartmental modelling to quantify intervention impacts during epidemics.\nReal-time forecasting and nowcasting of infections and \\(R_t\\) using Bayesian methods with tools like EpiNow2, epinowcast, epidemia, and EpiEstim.\nBuilding reproducible pipelines and open source packages for outbreak analytics and model implementation.\nImproving science research culture."
  },
  {
    "objectID": "research_projects.html#research-interests",
    "href": "research_projects.html#research-interests",
    "title": "Research",
    "section": "",
    "text": "I hold a PhD specialising in outbreak response modelling and decision-making. My work focuses on developing methods and open-source tools to evaluate the impact of pharmaceutical and non-pharmaceutical interventions on the spread of vaccine-preventable diseases.\nKey interests:\n\nCompartmental modelling to quantify intervention impacts during epidemics.\nReal-time forecasting and nowcasting of infections and \\(R_t\\) using Bayesian methods with tools like EpiNow2, epinowcast, epidemia, and EpiEstim.\nBuilding reproducible pipelines and open source packages for outbreak analytics and model implementation.\nImproving science research culture."
  },
  {
    "objectID": "research_projects.html#published-work",
    "href": "research_projects.html#published-work",
    "title": "Research",
    "section": "Published work",
    "text": "Published work\nYou can find my published work on my Google Scholar profile.\n\nRecent work\n\n\n\n\n\n\n\n\nTop 5 most cited publications"
  },
  {
    "objectID": "research_projects.html#ongoing-research-work",
    "href": "research_projects.html#ongoing-research-work",
    "title": "Research",
    "section": "Ongoing research work",
    "text": "Ongoing research work\n\nEvaluating the tradeoffs of using temporally aggregated data for epidemiological forecasts: a case study of COVID-19 in South Africa.\nA surveillance pipeline to detect changes in reported COVID-19 severity (case fatality, case hospitalization, and hospital fatality).\nAge-structured compartmental model for estimating the timing of detection of polio-related acute flaccid paralysis in South Africa (generalizable to other settings).\nA two-strain compartmental model for studying the impact of the timing of the emergence of variants on control strategies."
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#demonstration-epinow2-model-setup-and-execution",
    "href": "blog/epinow2-eval-guide/index.html#demonstration-epinow2-model-setup-and-execution",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Demonstration: EpiNow2 Model Setup and Execution",
    "text": "Demonstration: EpiNow2 Model Setup and Execution\n\nSetup: Data and epidemiological parameters\nTo estimate time-varying Rt, EpiNow2 requires: 1. Case data: Time series of reported cases 2. Epidemiological delays: Generation time, incubation period, and reporting delays 3. Prior distributions: Initial beliefs about Rt and other parameters\nLet‚Äôs set up these components:\n\n# Configure parallel processing for faster MCMC sampling\n# Use at most 4 cores, leaving 1 core free for system operations\noptions(mc.cores = min(4, parallel::detectCores() - 1))\n\n# Define epidemiological delay distributions\n# In practice, source these from literature or estimate from data\n\n# Generation time: time between successive infections in a transmission chain\n# Using Gamma distribution with uncertainty in parameters\ngeneration_time &lt;- Gamma(\n    shape = Normal(1.3, 0.3),    # Mean of ~3.5 days\n    rate = Normal(0.37, 0.09),   # Moderate spread\n    max = 14                      # Maximum generation interval\n)\n\n# Incubation period: time from infection to symptom onset\n# Using LogNormal distribution (common for incubation periods)\nincubation_period &lt;- LogNormal(\n    meanlog = Normal(1.6, 0.06), # Median ~5 days\n    sdlog = Normal(0.4, 0.07),   # Variability in incubation\n    max = 14                      # Maximum incubation period\n)\n\n# Reporting delay: time from symptom onset to case reporting\n# Accounts for testing, lab processing, and reporting lags\nreporting_delay &lt;- LogNormal(mean = 2, sd = 1, max = 10)\n\n# Load case data\n# Using first 60 days of example data to demonstrate workflow\n# In practice, use your complete outbreak data\nreported_cases &lt;- example_confirmed[1:60]\n\n# Visualize the input data\ncases_plots &lt;- ggplot(reported_cases, aes(x = date, y = confirm)) +\n    geom_col(fill = \"steelblue\", alpha = 0.7) +\n    labs(\n      title = \"Confirmed Cases: Input Data\",\n      x = \"Date\",\n      y = \"Reported Cases\"\n    ) +\n    theme_minimal() +\n    theme(plot.title = element_text(face = \"bold\"))\n\ncases_plots\n\n\n\n\n\n\n\n\n\n\nRunning the Rt estimation\nNow we fit the EpiNow2 model to estimate time-varying Rt and generate forecasts:\n\nout &lt;- epinow(\n    data = reported_cases,\n    generation_time = gt_opts(generation_time),\n    # Prior on initial Rt: LogNormal(mean=2, sd=0.1) suggests Rt ‚âà 2\n    rt = rt_opts(prior = LogNormal(mean = 2, sd = 0.1)),\n    # Combine incubation and reporting delays\n    delays = delay_opts(incubation_period + reporting_delay)\n)\n\nLogging threshold set at INFO for the name logger\nWriting EpiNow2 logs to the console and:\n'/var/folders/vr/dn4r1_zj417drd1zr9301trw0000gp/T//RtmpKjo8ww/regional-epinow/2020-04-21.log'.\nLogging threshold set at INFO for the name logger\nWriting EpiNow2.epinow logs to the console and:\n'/var/folders/vr/dn4r1_zj417drd1zr9301trw0000gp/T//RtmpKjo8ww/epinow/2020-04-21.log'.\n\n# Visualize Rt estimates and forecasts\n# This plot shows: estimated Rt over time, case nowcasts, and forecasts\nplot(out)\n\n\n\n\n\n\n\n\nThe plot above shows three key outputs: 1. Estimated Rt trajectory: How transmission intensity changed over time 2. Infections by date of infection: Nowcast accounting for reporting delays 3. Forecast: Predicted future cases with uncertainty intervals"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#step-1-mcmc-diagnostics-and-convergence-checks",
    "href": "blog/epinow2-eval-guide/index.html#step-1-mcmc-diagnostics-and-convergence-checks",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Step 1: MCMC Diagnostics and Convergence Checks",
    "text": "Step 1: MCMC Diagnostics and Convergence Checks\nBefore trusting our Rt estimates, we must verify that the Bayesian MCMC sampler converged properly. EpiNow2 uses Stan for inference, giving us access to Stan‚Äôs comprehensive diagnostic toolkit via the bayesplot and posterior packages.\n\nKey diagnostic metrics\nWe evaluate convergence using several complementary diagnostics:\n\nDivergent transitions. These should be minimized; ideally 0. Divergent transitions can be improved by tuning Stan controls like adapt_delta, max_treedepth, and stepsize in stan_opts(). If there are divergent transitions, increase adapt_delta (e.g., 0.95 or 0.99). See an in‚Äëdepth explanation at https://mc-stan.org/learn-stan/diagnostics-warnings.html.\nRhat. These should be close to 1 indicating good mixing. Rhat values should be less than 1.05 (See ?rstan::Rhat).\nTreedepth. This should be low; high values indicate potential issues with the model.\nESS values. These should be high; low values indicate insufficient sampling. In particular, both bulk‚ÄëESS and tail‚ÄëESS should be at least ~100 per chain to ensure reliable posterior quantile estimates (see ?rstan::ess_bulk).\n\n\n# Extract the Stan fit object from EpiNow2 output\nfit &lt;- out$estimates$fit\n\n# Extract NUTS sampler parameters (No-U-Turn Sampler - Stan's HMC variant)\nnp &lt;- bayesplot::nuts_params(fit)\ndivergence_data &lt;- subset(np, Parameter == \"divergent__\")  # Sampling failures\ntreedepth_data &lt;- subset(np, Parameter == \"treedepth__\")    # Trajectory lengths\n\n# Compute convergence metrics for all parameters\n# Rhat: measures between-chain vs within-chain variance\n# ESS: effective sample size (accounts for autocorrelation)\nposterior_summary &lt;- posterior::summarize_draws(\n    fit, c(posterior::default_convergence_measures(), \"ess_basic\")\n) |&gt; subset(variable != \"lp__\")  # Exclude log-probability\n\n# Extract minimum ESS values across all parameters\n# Worst-case ESS determines overall inference reliability\nfit_ess_basic &lt;- min(posterior_summary$ess_basic, na.rm = TRUE)\nfit_ess_bulk &lt;- min(posterior_summary$ess_bulk, na.rm = TRUE)\nfit_ess_tail &lt;- min(posterior_summary$ess_tail, na.rm = TRUE)\n\n# Compile diagnostic summary table\ndiagnostics &lt;- data.table(\n    \"samples\" = nrow(np) / length(unique(np$Parameter)),  # Total post-warmup samples\n    \"max_rhat\" = round(max(posterior_summary$rhat, na.rm = TRUE), 3),  # Worst Rhat\n    \"divergent_transitions\" = sum(divergence_data$Value),  # Count of divergences\n    \"per_divergent_transitions\" = mean(divergence_data$Value),  # Proportion divergent\n    \"max_treedepth\" = max(treedepth_data$Value),  # Maximum tree depth reached\n    \"ess_basic\" = fit_ess_basic,  # Basic ESS\n    \"ess_bulk\" = fit_ess_bulk,    # ESS for bulk of distribution\n    \"ess_tail\" = fit_ess_tail     # ESS for distribution tails\n)\n\n# Calculate tree depth saturation\n# High proportion indicates sampler hitting computational limits\ndiagnostics[, no_at_max_treedepth :=\n                sum(treedepth_data$Value == max_treedepth)\n][, per_at_max_treedepth := no_at_max_treedepth / samples]\n\nknitr::kable(diagnostics)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsamples\nmax_rhat\ndivergent_transitions\nper_divergent_transitions\nmax_treedepth\ness_basic\ness_bulk\ness_tail\nno_at_max_treedepth\nper_at_max_treedepth\n\n\n\n\n2000\n1.01\n0\n0\n9\n1325.989\n1277.945\n1109.327\n837\n0.4185\n\n\n\n\n\n\n\nInterpreting the diagnostics\nThe diagnostics table above summarizes key MCMC performance metrics. For reliable Rt estimates, we should see:\n\nmax_rhat &lt; 1.05: Our example shows good convergence (Rhat values close to 1.0)\ndivergent_transitions = 0: No divergent transitions is ideal. Any divergences suggest the sampler struggled with the posterior geometry\nESS values &gt; 400 (for 4 chains √ó 1000 samples): Bulk-ESS and tail-ESS should be at least 100 per chain. Higher is better for reliable inference\nper_at_max_treedepth &lt; 0.01: Few samples hitting maximum tree depth indicates efficient sampling\n\nBased on these criteria, we can assess whether our Rt estimates are trustworthy.\n\n\nVisual MCMC diagnostics\nWhile numerical summaries are useful, visual diagnostics provide deeper insight into sampler behavior. Let‚Äôs examine trace plots and rank plots for key parameters:\n\n# Extract key Rt parameters for visualization\n# Using a subset of timepoints for clarity\nlibrary(bayesplot)\ncolor_scheme_set(\"mix-blue-red\")\n\n# Trace plots show MCMC sampling behavior over iterations\n# Good mixing appears as \"fuzzy caterpillars\" with chains overlapping\nmcmc_trace(fit, pars = c(\"R[1]\", \"R[15]\", \"R[30]\", \"R[45]\"),\n           facet_args = list(ncol = 2, strip.position = \"left\"))\n\n\n\n\n\n\n\n\n\n# Rank plots check for uniform distribution of ranks across chains\n# Deviations from uniform indicate convergence issues\nmcmc_rank_overlay(fit, pars = c(\"R[1]\", \"R[15]\", \"R[30]\", \"R[45]\"))\n\n\n\n\n\n\n\n\nWell-mixed chains should show: - Trace plots: Overlapping ‚Äúfuzzy caterpillar‚Äù patterns with no trends or stuck chains - Rank plots: Uniform distribution of ranks across all chains (no systematic patterns)\n\n\n\n\n\n\nWhat if diagnostics fail?\n\n\n\nIf diagnostics reveal problems (high Rhat, low ESS, divergences):\n\nIncrease sampling: Use stan_opts(chains = 4, iter_sampling = 4000) for more samples\nAdjust sampler settings: Increase adapt_delta (e.g., 0.95 or 0.99) to reduce divergences\nCheck model specification: Ensure delay distributions and priors are reasonable\nIncrease max_treedepth: Use stan_opts(max_treedepth = 12) if hitting limits\nConsult Stan diagnostics guide: https://mc-stan.org/misc/warnings.html\n\nDo not use Rt estimates with failing diagnostics‚Äîthey may be severely biased!"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#step-2-forecast-performance-evaluation",
    "href": "blog/epinow2-eval-guide/index.html#step-2-forecast-performance-evaluation",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Step 2: Forecast Performance Evaluation",
    "text": "Step 2: Forecast Performance Evaluation\nForecast performance can be evaluated by comparing the forecast of reported cases with the observed cases using Proper Scoring Rules(Gneiting and Raftery 2007; Carvalho 2016) such as the Continuous Ranked Probability Score (CRPS) and Weighted Interval Score (WIS). These are available via the scoringutils::score() function.\nThe scoringutils::score() function requires a dataset that contains at least the following columns:\n\ndate: the date of the forecast\nprediction: forecast values\ntrue_value: the observed values\nquantile: If evaluating quantiles, the quantile of the forecasted values (e.g., median, lower and upper bounds), in ascending order.\n\nLet‚Äôs extract and prepare the forecasts and corresponding observed cases for the evaluation.\nEpiNow2‚Äôs epinow() function returns a list of model outputs in the raw and several summarised formats for various use cases. In particular, there are time series of ‚Äúinfections‚Äù, ‚Äúreported_cases‚Äù, ‚Äúgrowth_rate‚Äù, and ‚ÄúR‚Äù, all grouped into ‚Äúestimate‚Äù, ‚Äúestimate based on partial data‚Äù, and ‚Äúforecast‚Äù.\nHere, we‚Äôre interested in the ‚Äúforecast‚Äù type of the ‚Äúreported_cases‚Äù variable, including the median and quantiles (lower and upper bounds).\n\n# Extract the forecasts\nforecasts &lt;- out$estimates$summarised[variable == \"reported_cases\"][type == \"forecast\", ] %&gt;% \n    select(-c(mean, sd, variable, strat, type))\n\nLet‚Äôs also extract the corresponding subset of the observed data.\n\n# Extract observed cases for the same period\nobs_data &lt;- example_confirmed[date &gt;= min(forecasts$date) & date &lt;= max(forecasts$date)]\n\n\nVisualizing forecasts against observations\nBefore scoring, let‚Äôs visualize how well our forecasts align with observed data:\n\n# Prepare data for plotting\nplot_data &lt;- merge(forecasts, obs_data, by = \"date\", all.x = TRUE)\n\n# Create forecast vs observed plot\nggplot(plot_data, aes(x = date)) +\n  # Prediction intervals (90%, 50%, 20%)\n  geom_ribbon(aes(ymin = lower_90, ymax = upper_90), alpha = 0.2, fill = \"steelblue\") +\n  geom_ribbon(aes(ymin = lower_50, ymax = upper_50), alpha = 0.3, fill = \"steelblue\") +\n  geom_ribbon(aes(ymin = lower_20, ymax = upper_20), alpha = 0.4, fill = \"steelblue\") +\n  # Median forecast\n  geom_line(aes(y = median), color = \"steelblue\", size = 1) +\n  # Observed data\n  geom_point(aes(y = confirm), color = \"black\", size = 2) +\n  geom_line(aes(y = confirm), color = \"black\", linetype = \"dashed\") +\n  labs(\n    title = \"EpiNow2 Forecast vs Observed Cases\",\n    subtitle = \"Shaded regions show 20%, 50%, and 90% prediction intervals\",\n    x = \"Date\",\n    y = \"Reported Cases\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\"))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nIdeally, observed values (black points) should fall mostly within the prediction intervals, especially the wider ones. Systematic deviations suggest model miscalibration.\n\n\nPreparing data for scoring\nNow, let‚Äôs combine the extracted forecasts with the observed data and clean up the quantiles into a format suitable for use with scoringutils. We will be cleaning them up because the forecasts data.table labels the quantiles as lower_20, upper_20, etc., where the number indicates the quantile level (e.g., 50% for the median), but that is not compatible with scoringutils.\n\n# Combine forecasts with observed cases\neval_dt &lt;- merge(forecasts, obs_data, by = \"date\")[, true_value := confirm][, confirm := NULL]\n\n# Melt the data to long format\ncols_to_melt &lt;- c(\"median\", grep(\"^(lower|upper)_\", names(eval_dt), value = TRUE))\neval_long &lt;- melt(\n    eval_dt,\n    id.vars = setdiff(names(eval_dt), cols_to_melt),\n    measure.vars = cols_to_melt,\n    variable.name = \"prediction\",\n    value.name = \"value\"\n)\n\n# Prepare the evaluation data\neval_long[, quantile := fifelse(\n  prediction == \"median\", 0.5,\n  fifelse(\n    grepl(\"^lower_\", prediction),\n    (1 - as.numeric(sub(\"lower_\", \"\", prediction)) / 100) / 2,\n    fifelse(\n      grepl(\"^upper_\", prediction),\n      (1 + as.numeric(sub(\"upper_\", \"\", prediction)) / 100) / 2,\n      NA_real_\n    )\n  )\n)][, prediction := value][, value := NULL]\n\nWarning in fifelse(grepl(\"^lower_\", prediction), (1 - as.numeric(sub(\"lower_\",\n: NAs introduced by coercion\n\n\nWarning in fifelse(grepl(\"^upper_\", prediction), (1 + as.numeric(sub(\"upper_\",\n: NAs introduced by coercion\n\n# Sort the data by quantile\nsetorder(eval_long, quantile) %&gt;% \n    head(10)\n\n          date true_value prediction quantile\n        &lt;Date&gt;      &lt;num&gt;      &lt;num&gt;    &lt;num&gt;\n 1: 2020-04-22       2729    1526.00     0.05\n 2: 2020-04-23       3370    1623.90     0.05\n 3: 2020-04-24       2646    1911.95     0.05\n 4: 2020-04-25       3021    1599.00     0.05\n 5: 2020-04-26       2357    1701.95     0.05\n 6: 2020-04-27       2324    1507.00     0.05\n 7: 2020-04-28       1739    1237.85     0.05\n 8: 2020-04-22       2729    1895.00     0.25\n 9: 2020-04-23       3370    2056.75     0.25\n10: 2020-04-24       2646    2420.00     0.25\n\n\nNow we can use the scoringutils package to compute and summarise the scores. By default, a range of scores will be computed, including the interval_score, dispersion, underprediction, overprediction, coverage_deviation, bias, and ae_median.\n\n# Mainly uses the scoringutils package\nscored_scores &lt;- eval_long[, quantile_level := quantile][, quantile := NULL][, model := \"EpiNow2\"] |&gt; # align names to scoringutils preference\n    as_forecast_quantile(observed  = \"true_value\", predicted = \"prediction\") |&gt; \n    score() %&gt;%\n    summarise_scores()\n\nWarning: ! Computation for `interval_coverage_90` failed. Error: ! To compute the\n  interval coverage for an interval range of \"90%\", the 0.05 and 0.95 quantiles\n  are required.\n\nknitr::kable(scored_scores, digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\nwis\noverprediction\nunderprediction\ndispersion\nbias\ninterval_coverage_50\nae_median\n\n\n\n\nEpiNow2\n313.898\n33.963\n150.892\n129.043\n-0.143\n0.571\n444.286"
  },
  {
    "objectID": "blog/epinow2-eval-guide/index.html#conclusion-validation-checklist",
    "href": "blog/epinow2-eval-guide/index.html#conclusion-validation-checklist",
    "title": "How to Validate Time-Varying Reproduction Number Estimation in EpiNow2: MCMC Diagnostics, Convergence, and Forecast Evaluation",
    "section": "Conclusion: Validation Checklist",
    "text": "Conclusion: Validation Checklist\nWe‚Äôve demonstrated a comprehensive three-pillar approach to validating EpiNow2 Rt estimates. Use this checklist to assess whether your model results are reliable:\n\n‚úì MCMC Diagnostics Pass\n\nRhat &lt; 1.05 for all parameters (ideally &lt; 1.01)\nZero divergent transitions (or &lt; 1% if unavoidable)\nESS bulk and tail &gt; 400 total (&gt;100 per chain minimum)\nLow tree depth saturation (&lt; 1% hitting max_treedepth)\nTrace plots show good mixing (fuzzy caterpillars)\nRank plots show uniform distribution\n\n\n\n‚úì Forecast Evaluation Complete\n\nVisual inspection shows forecasts align with observations\nPrediction intervals contain observed values at appropriate rates\nScoring metrics calculated (interval score, bias, coverage)\nComparison to baseline (if available) shows improvement\n\n\n\n‚úì Interpretation and Documentation\n\nRt trajectory makes epidemiological sense\nUncertainty intervals are appropriate (not too narrow/wide)\nModel assumptions documented (delays, priors)\nLimitations acknowledged\n\nWhen to trust your Rt estimates: Only when all diagnostic checks pass and forecast evaluation is satisfactory. Failing diagnostics or poor forecast performance indicate model issues that must be resolved before drawing conclusions.\nWhen to seek help: If diagnostics consistently fail despite tuning, or forecasts systematically miss observations, consult the Stan community forums or EpiNow2 GitHub discussions."
  }
]